---
permalink: /
title: "Hey, I'm Sascha."
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a  Machine Learning Researcher at the University of Mannheim in Germany, where I have been pursuing my PhD since 2019. My research is centered on advancing machine learning techniques for tabular data, with a recent focus on gradient-based decision tree learning and tree-based ensemble methods.

Research Interests
======
My current work involves developing a new approach for learning hard, axis-aligned decision trees using gradient descent. This method employs backpropagation with a straight-through operator on a dense decision tree representation, allowing for the joint optimization of all tree parameters. As a result, we achieve state-of-the-art performance across various domains, including interpretable decision trees and high-performance decision tree ensembles for tabular data, as well as interpretable reinforcement learning without information loss.

My primary research interests include:
* Ensemble Methods
* Tree-Based Methods
* Deep Learning for Tabular Data
* Time-Series Forecasting
* Explainable Artificial Intelligence

News
======

First Author Publications
======
[Mitigating Information Loss in Tree-Based Reinforcement Learning via Direct Optimization](https://openreview.net/forum?id=qpXctF2aLZ)
<u>Sascha Marton</u>, Tim Grams, Florian Vogt, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt
ICLR 2025 <b>(Spotlight)</b>

[Decision Trees That Remember: Gradient-Based Learning of Recurrent Decision Trees with Memory](https://openreview.net/forum?id=u2Hh24rxW1)
<u>Sascha Marton</u>, Moritz Schneider, Jannik Brinkmann, Stefan Ludtke, Christian Bartelt, Heiner Stuckenschmidt
ICLR 2025 Workshop on New Frontiers in Associative Memories

[GRANDE: Gradient-Based Decision Tree Ensembles for Tabular Data](https://openreview.net/forum?id=XEFWBxi075)
<u>Sascha Marton</u>, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt
ICLR 2024

[GradTree: Learning Axis-Aligned Decision Trees with Gradient Descent](https://ojs.aaai.org/index.php/AAAI/article/view/29345)
<u>Sascha Marton</u>, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt
AAAI 2024 <b>(Oral)</b>

[Explaining neural networks without access to training data](https://link.springer.com/article/10.1007/s10994-023-06428-4)
<u>Sascha Marton</u>, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt
Machine Learning Journal (2024)

[Explanations for Neural Networks by Neural Network](https://www.mdpi.com/2076-3417/12/3/980)
<u>Sascha Marton</u>, Stefan Lüdtke, Christian Bartelt
Applied Sciences (2022)

Further Publications
======

[Beyond Pixels: Enhancing LIME with Hierarchical Features and Segmentation Foundation Models](https://openreview.net/forum?id=JHs5p6nPbG)
Patrick Knab, <u>Sascha Marton</u>, Christian Bartelt
ICLR 2025 Workshop on Foundation Models in the Wild

[A Data-Centric Perspective on Evaluating Machine Learning Models for Tabular Data](https://openreview.net/forum?id=kWTvdSSH5W)
Andrej Tschalzev, <u>Sascha Marton</u>, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt
NeurIPS 2024

[DCBM: Data-Efficient Visual Concept Bottleneck Models](https://arxiv.org/abs/2412.11576)
Katharina Prasse, Patrick Knab, <u>Sascha Marton</u>, Christian Bartelt, Margret Keuper
arXiv preprint

[Interpreting Outliers in Time Series Data through Decoding Autoencoder](https://ceur-ws.org/Vol-3761/paper3.pdf)
Patrick Knab, <u>Sascha Marton</u>, Christian Bartelt, Robert Fuder
ECML-PKDD 2024 Workshop on Explainable AI for Time Series and Data Streams 

[Bias mitigation for large language models using adversarial learning](https://ceur-ws.org/Vol-3523/paper11.pdf)
Jasmina S Ernst, <u>Sascha Marton</u>, Jannik Brinkmann, Eduardo Vellasques, Damien Foucard, 
Martin Kraemer, Marian Lambert
ECAI 2023 Workshop on Fairness and Bias in AI
